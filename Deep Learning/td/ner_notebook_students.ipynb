{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f862cc2b-2716-461d-b313-9c4390166c44",
   "metadata": {},
   "source": [
    "# TD - Word embedding and RNN network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc45a22b-b282-46d4-872c-0b93707f165e",
   "metadata": {},
   "source": [
    "## 0. The different imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2747f9-fda1-41ad-a521-f68d2a503f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ed85c-edf5-44f8-ac25-910312e728f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0eee00-058d-4e14-8872-bc8e996d2f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "from keras import models, layers, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139208a8-437b-44b6-8b0a-be40b8d85376",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import gensim\n",
    "except:\n",
    "    !pip install gensim\n",
    "    import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d8df9a-f037-444d-81a5-32155d84fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api # from\n",
    "\n",
    "_EMBEDDING_SIZE = 50\n",
    "\n",
    "# Download if not exists\n",
    "if not os.path.exists(\"glove-wiki-gigaword-\"+str(_EMBEDDING_SIZE)+\".kv\"):\n",
    "    print(\"Download\")\n",
    "    word_vectors = api.load(\"glove-wiki-gigaword-\"+str(_EMBEDDING_SIZE))\n",
    "    word_vectors.save(\"glove-wiki-gigaword-\"+str(_EMBEDDING_SIZE)+\".kv\")\n",
    "else:\n",
    "    # Load the model\n",
    "    print(\"Load\")\n",
    "    word_vectors = KeyedVectors.load(\"glove-wiki-gigaword-\"+str(_EMBEDDING_SIZE)+\".kv\", mmap='r')\n",
    "\n",
    "# fix vocabulary size\n",
    "_VOCABULARY_SIZE = len(word_vectors.key_to_index)\n",
    "_VOCABULARY_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9631fde-1065-49ae-bc28-f02e78ae766b",
   "metadata": {},
   "source": [
    "## 1. The magic of good embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d408ed6e-0cc4-4737-855b-12908f71d277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embedding of a word\n",
    "word_vectors['university']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6bfb9-d56c-4c7d-b3b3-a568da69ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most similar words\n",
    "word_vectors.most_similar('university')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41c46a5-27a3-4b1e-9e06-ff36263cb8ae",
   "metadata": {},
   "source": [
    "**Un peu de calcul avec les vecteurs**\n",
    "![woman-man+king](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTDeOAaVruIywX9lhjqdfWZ70iSMTYX-3eW5g&s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ef0f7e-c1ed-4670-9b23-ef9dbf679058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playing with vectors\n",
    "word_vectors.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9cb4b1-7fc2-4bea-a346-f305520107dc",
   "metadata": {},
   "source": [
    "**En voici un autre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022b673a-7ed6-4a2c-8cb7-638dd5144740",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors.most_similar(positive=['rome', 'france'], negative=['italy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e92142-0081-42ad-b9d2-5e1af06457fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Essayer de trouver d'autres triplets qui fonctionnent et publiez les sur slack \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efabbe6-7d92-4995-a1bc-7a265ed75840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the hidden word\n",
    "word_vectors.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab99131-26c0-431b-9e8c-7c9de1afa467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the hidden word\n",
    "word_vectors.doesnt_match(\"monday tuesday friday sunday\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af66caa-6737-4eb2-8813-119cf2bdc98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Essayer de trouver d'autres ensemble de mots avec un mot incongru bien détecté et publiez le sur slack \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf6135c-3a39-4dbc-93d2-18d21ebc0448",
   "metadata": {},
   "source": [
    "## 2. Build a RNN for a NER Task\n",
    "\n",
    "NER seeks to extract and classify words into predefined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, etc.\n",
    "\n",
    "![NER task](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Rhj-zxvJGG_Pw7cQSoa6w.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5491a6-35eb-4826-b14c-0e986d914448",
   "metadata": {},
   "source": [
    "### 2.1 Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beeefc9-9c82-49b5-b656-67e0df981528",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\")\n",
    "data = data.fillna(method=\"ffill\")\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a11e380-356e-4bfd-b11e-6e4ad482531a",
   "metadata": {},
   "source": [
    "#### Retrieve sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b663974-343f-4a1e-900c-5014ce4e5160",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb20153-83cb-4895-a34b-7399861e554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ba4365-b751-461c-a139-e8cb2cb6e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00de94e0-6b0d-4b2d-a30b-f699e05fe58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset before working\n",
    "\n",
    "TRAIN, TEST = train_test_split(sentences, test_size=0.2, random_state=42)\n",
    "TRAIN, VAL = train_test_split(TRAIN, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9f82ff-dc7a-415a-b9a5-aa39a137ba8f",
   "metadata": {},
   "source": [
    "### 2.2 A Simple recurrent neural network for NER task\n",
    "\n",
    "![RNN for NER](https://confusedcoders.com/wp-content/uploads/2019/12/many_to_many-1024x530.png)\n",
    "\n",
    "* Red: embedding layer\n",
    "* Green: recurrent cells\n",
    "* Blue: dense cells\n",
    "\n",
    "La manière la plus simple de procéder est de considérer que nous avons à notre disposition uniquement les données d'entrainement et que nous utilisons la couche d'embedding de Keras. Néanmoins, un mot doit être représenté par un nombre. Commençon donc par transformer chacun des mots de nos données d'entrainement par un nombre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46477b9c-0c4e-46b8-a66c-207493c5ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vocabulary from the train part\n",
    "words = [\"<PAD>\", \"<UNK>\"]+sorted(list({w[0] for s in TRAIN for w in s}))\n",
    "_NUM_WORDS = len(words)\n",
    "print(\"Unique words in corpus:\", _NUM_WORDS)\n",
    "\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "idx2word = {v:k for k, v in word2idx.items()}\n",
    "\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bff083-7a18-4b93-bb4b-baee39b251e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tags from the train part\n",
    "\n",
    "tags = [\"<PAD>\"]+sorted(list({w[2] for s in TRAIN for w in s}),reverse=True)\n",
    "_NUM_TAGS = len(tags)\n",
    "print(\"Unique tags in corpus:\", _NUM_TAGS)\n",
    "\n",
    "tag2idx = {w: i for i, w in enumerate(tags)}\n",
    "idx2tag = {v:k for k, v in tag2idx.items()}\n",
    "\n",
    "tags[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f0387-7a23-4427-9d04-ce38acece734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max_len without truncation for the train\n",
    "\n",
    "_MAX_LEN = max([len(sent) for sent in TRAIN])\n",
    "_MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fad3716-c892-4986-9831-c643b71abad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(maxlen=_MAX_LEN,\n",
    "                        sequences=[[word2idx[w[0]] if word2idx.get(w[0]) is not None else word2idx[\"<UNK>\"] for w in s] for s in TRAIN],\n",
    "                        padding=\"pre\", truncating=\"post\",\n",
    "                        value=word2idx[\"<PAD>\"])\n",
    "                        # padding=\"pre\" and truncating=\"pre\" by default\n",
    "\n",
    "y_train = pad_sequences(maxlen=_MAX_LEN,\n",
    "                        sequences=[[tag2idx[w[2]] for w in s] for s in TRAIN],\n",
    "                        padding=\"pre\", truncating=\"post\",\n",
    "                        value=tag2idx[\"<PAD>\"])\n",
    "\n",
    "X_val = pad_sequences(maxlen=_MAX_LEN,\n",
    "                      sequences=[[word2idx[w[0]] if word2idx.get(w[0]) is not None else word2idx[\"<UNK>\"] for w in s] for s in VAL],\n",
    "                      padding=\"pre\", truncating=\"post\", value=word2idx[\"<PAD>\"])\n",
    "\n",
    "y_val = pad_sequences(maxlen=_MAX_LEN,\n",
    "                        sequences= [[tag2idx[w[2]] for w in s] for s in VAL],\n",
    "                        padding=\"pre\", truncating=\"post\", value=tag2idx[\"<PAD>\"])\n",
    "\n",
    "X_test = pad_sequences(maxlen=_MAX_LEN,\n",
    "                       sequences=[[word2idx[w[0]] if word2idx.get(w[0]) is not None else word2idx[\"<UNK>\"] for w in s] for s in TEST],\n",
    "                       padding=\"pre\", truncating=\"post\", value=word2idx[\"<PAD>\"])\n",
    "\n",
    "y_test = pad_sequences(maxlen=_MAX_LEN,\n",
    "                       sequences=[[tag2idx[w[2]] for w in s] for s in TEST],\n",
    "                       padding=\"pre\", truncating=\"post\", value=tag2idx[\"<PAD>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab9b9c3-82a2-47ab-9432-d0c2a6bdc090",
   "metadata": {},
   "source": [
    "#### Un premier réseau RNN\n",
    "\n",
    "Bon, j'ai fait tout le travail préparatoire pour vous. A vous de jouer et de remplacer les ... par le code correct.\n",
    "\n",
    "Il est possible d'ajouter du dropout sur la couche récurrente pour limiter l'overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378e3455-832b-4cfb-a594-88f9ad2836bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_HIDDEN_SIZE = 32\n",
    "_DROPOUT = 0.4\n",
    "\n",
    "inputs = layers.Input(shape=(_MAX_LEN,), dtype=int)\n",
    "emb = layers.\"...\"        # Embedding step\n",
    "assert emb.shape==(None, 104, 50)\n",
    "\n",
    "hidden = layers.\"...\"     # Recurrent step\n",
    "assert hidden.shape==(None, 104, 32)\n",
    "\n",
    "outputs = layers.\"...\"    # Output step\n",
    "assert hidden.shape==(None, 104, 17)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b8c118-4ed3-4ed1-b3b8-0324f3d3275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" On compile avec la bonne fonction de cout \"\"\"\n",
    "model.compile(optimizer=\"adam\", loss=...)\n",
    "\n",
    "\"\"\" On entraine jusqu'au début de l'overfitting \"\"\"\n",
    "history = model.fit(X_train, y_train, validation_data=[X_val, y_val], epochs=1000,\n",
    "          callbacks=[callbacks.EarlyStopping(...)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f499766-81e9-4395-832a-9322b8c86190",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" on verifie que le réseau apprend mais pas trop vite \"\"\"\n",
    "\n",
    "\"\"\" Ayant peu de données, le réseau apprend relativement vite en 5-6 epoques \"\"\"\n",
    "\n",
    "\"\"\" Avez-vous remarqué, que le temps d'apprentissage est nettement plus lent\n",
    "qu'avec des cellules Dense \"\"\"\n",
    "\n",
    "def babysit(history):    \n",
    "    plt.plot(history['loss'], label=\"loss\")\n",
    "    plt.plot(history['val_loss'], label=\"val_loss\")\n",
    "    plt.show()\n",
    "\n",
    "babysit(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aa45dc-9922-4957-9f27-f53af0aeb8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" On évalue les performances en éliminant la classe 'O' omni-présente\n",
    "et bien évidement le padding \"\"\"\n",
    "y_pred = np.argmax(model.predict(X_test), axis=2)\n",
    "print(classification_report(y_test.flatten(), y_pred.flatten(), zero_division=0.0,\n",
    "                            target_names=tags[2:], labels=range(2,len(tags)), digits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dc367c-663f-4ef2-97be-e06dfba8d3d8",
   "metadata": {},
   "source": [
    "### 2.3 A bidirectionnal recurrent neural network for NER task\n",
    "\n",
    "![BiLSTM](https://www.researchgate.net/publication/332375961/figure/fig3/AS:746852529999875@1555074927914/A-biLSTM-network-for-NER-tasks-English-Translation-Taxquenas-Soriana-has-fallen-down.ppm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140a233f-fb33-4caf-8a44-2908d68d4876",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" A vous de jouer \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6081ef8-df7e-4cec-85b0-9ee746f6712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"...\")\n",
    "history = model.fit(X_train, y_train, validation_data=[X_val, y_val], epochs=1000,\n",
    "          callbacks=[callbacks.EarlyStopping(...)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c38247-faf4-47f7-8067-1ee3dbf93a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "babysit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20348e41-b0b5-403c-b53f-3653784ac9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation without tags 'O' and padding\n",
    "y_pred = np.argmax(model.predict(X_test), axis=2)\n",
    "print(classification_report(...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5a8ee9-fc4d-4ba9-ae97-7bb2788c340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Est-ce que l'on fait mieux que précédemment,\n",
    "en particulier pour les classes sous représentées \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1835bb-8abd-454f-a294-a1569b6be793",
   "metadata": {},
   "source": [
    "### 2.4 A Stacked recurrent neural network for NER task\n",
    "\n",
    "Même chose mais avec plusieurs couches récurrentes, par exemple une première couche avec un BI-LSTM qui effectue la moyenne des deux sorties (cf. doc Bidirectional layer, parametre merge_mod) et une seconde couche avec un GRU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901a0b01-b51f-4170-9c22-ba90d122cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" A vous de jouer \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95822bbb-c5a2-4dc6-9429-f705af39692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=...)\n",
    "history = model.fit(X_train, y_train, validation_data=[X_val, y_val], epochs=1000,\n",
    "          callbacks=[callbacks.EarlyStopping(...)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ccad90-1795-4fa8-a123-1bf4fd24ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "babysit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b294b1-91e5-4340-b0fc-cd73852f1833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress tags 'O' and padding\n",
    "y_pred = np.argmax(model.predict(X_test), axis=2)\n",
    "print(classification_report(...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bba040-d45c-4e36-afae-c48fa17e02ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Avez-vous progressé ? Ce n'est pas certain... parfois un réseau simple fonctionne\n",
    "mieux qu'un réseau trop sophistiqué \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ee3e48-35e0-4994-8410-6e08cc04b409",
   "metadata": {},
   "source": [
    "### 2.5 How to use a pre-trained embedding\n",
    "\n",
    "Si on souhaite utiliser un embedding existant, le plus efficace est d'initialiser la couche d'embedding avec ces poids. Pour cela, il faut redéfinir le mapping mot-id afin qu'il corresponde à celui utilisé pour l'entrainement de l'embedding utilisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9b152b-8a8f-46cf-b409-d86f5335b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rappel\n",
    "# _VOCABULARY_SIZE contient la taille du vocabulaire de l'embedding pré-entrainé utilisé\n",
    "# word_vectors contient le vocabulaire et les différents vecteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bc087e-1e38-4cea-b4b8-d0e494481f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redéfinition du mapping mot-id\n",
    "\n",
    "# On peut obtenir la liste \"ordonnée\" des mots de la manière suivante\n",
    "words = [\"<PAD>\", \"<UNK>\"]+word_vectors.index_to_key\n",
    "_NUM_WORDS = len(words)\n",
    "print(\"Unique words in corpus:\", _NUM_WORDS)\n",
    "\n",
    "# Les dictionnaires permettant de passer d'un mot à son index (ou l'inverse)\n",
    "# sont les suivants : \n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "idx2word = {v:k for k, v in word2idx.items()}\n",
    "\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e6192d-7a50-4e7a-a344-4f598e835d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redéfinition des vecteurs d'entrainement\n",
    "X_train = ...\n",
    "\n",
    "X_val = ...\n",
    "\n",
    "X_test = ...\n",
    "\n",
    "# Inutile de modifier y_train, y_val, y_test\n",
    "# le mapping tag-id n'ayant pas été modifié"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98246d16-6620-4f3a-9beb-5456c7b28bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la matrice d'embedding\n",
    "embedding_matrix = np.zeros((_NUM_WORDS, _EMBEDDING_SIZE))\n",
    "\n",
    "\"\"\" reste à initialiser la matrice d'embedding \"\"\"\n",
    "A vous de jouer ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d890ff2-0209-4298-9da9-8a83dedaad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boucle de vérification\n",
    "import random\n",
    "for i, r in enumerate([random.randint(0, _NUM_WORDS) for _ in range(20)]):\n",
    "    assert np.array_equal(word_vectors[idx2word[r]],embedding_matrix[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfb4678-8397-4ad1-bd9f-4c55edb65d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du reseau - seul changement,\n",
    "# Pensez à initialiser la couche d'embedding  avec la matrice d'embedding\n",
    "# Un petit coup d'oeil à la doc Keras Embedding pour trouver le paramètre\n",
    "\"\"\" a vous de jouer \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b389dae8-e817-40f3-9d45-3c5a2d2db3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(...)\n",
    "history = model.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a160d3-9099-4114-83e0-53e2a8c70ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "babysit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c857b5b4-dd6f-4270-8c5f-64bfdc98b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress tags 'O' and padding\n",
    "y_pred = ...\n",
    "print(classification_report(...)), digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da0e41-6885-422c-90e8-117ef50e8be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Est-ce que l'on fait mieux que dans les cas précédents ?\n",
    "Si ce n'est pas le cas, il peut être interessant de regarder si le vocabulaire\n",
    "utilisé dans l'embedding correspond à celui du jeu de données \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
